{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 16:16:02.807121: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-28 16:16:02.828456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-28 16:16:02.853503: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-28 16:16:02.861167: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-28 16:16:02.880350: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-28 16:16:04.092188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 160\n",
      "Test set size: 40\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# MNIST 데이터 불러오기\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = mnist.load_data()\n",
    "\n",
    "# 데이터 정규화 (0-255 값을 0-1 사이로)\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test_full = X_test_full.astype('float32') / 255.0\n",
    "\n",
    "#torch.transform / normalize // imagenet mean sd \n",
    "\n",
    "# 숫자 1과 7만 선택하는 마스크 생성\n",
    "train_mask = np.isin(y_train_full, [1, 7])\n",
    "X_train, y_train = X_train_full[train_mask], y_train_full[train_mask]\n",
    "\n",
    "test_mask = np.isin(y_test_full, [1, 7])\n",
    "X_test, y_test = X_test_full[test_mask], y_test_full[test_mask]\n",
    "\n",
    "# 시드 고정 (예: 42로 고정)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2000개의 데이터를 무작위로 선택\n",
    "num_samples = 200\n",
    "indices = np.random.choice(len(X_train), num_samples, replace=False)\n",
    "X_sampled, y_sampled = X_train[indices], y_train[indices]\n",
    "\n",
    "# 2000개의 샘플에서 train/test 데이터 분할 (80% train, 20% test 비율로 나눔)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sampled, y_sampled, stratify=y_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 결과\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 크기로 겹치지 않게 패치로 나누는 함수\n",
    "def split_into_non_overlapping_patches(image, patch_size=(4, 4)):\n",
    "    patches = []\n",
    "    for i in range(0, image.shape[0], patch_size[0]):\n",
    "        for j in range(0, image.shape[1], patch_size[1]):\n",
    "            patch = image[i:i+patch_size[0], j:j+patch_size[1]].flatten()\n",
    "            patches.append(patch)\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지를 2x2 겹치지 않는 패치로 나누기\n",
    "X_train = np.array([split_into_non_overlapping_patches(img) for img in X_train])\n",
    "X_test = np.array([split_into_non_overlapping_patches(img) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 81, 7: 79}\n"
     ]
    }
   ],
   "source": [
    "# y_train이 numpy 배열일 경우\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 20, 7: 20}\n"
     ]
    }
   ],
   "source": [
    "# y_train이 numpy 배열일 경우\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 49, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Self-Attention and Binary Classifier from previous code\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert self.head_dim * heads == embed_size, \"Embedding size must be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask=None):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        # Split embedding into multiple heads\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "# Classifier model\n",
    "class SimpleSelfAttentionClassifier(nn.Module):\n",
    "    def __init__(self, embed_size=16, heads=2, num_classes=2):\n",
    "        super(SimpleSelfAttentionClassifier, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.fc = nn.Linear(embed_size * 49, num_classes)  # 49 is the sequence length in X_train\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output = self.attention(x, x, x)\n",
    "        attention_output = attention_output.flatten(start_dim=1)  # Flatten to feed into classifier\n",
    "        out = self.fc(attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, loss, optimizer\n",
    "model = SimpleSelfAttentionClassifier(embed_size=16, heads=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: attention.values.weight\n",
      "Shape: torch.Size([8, 8])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.keys.weight\n",
      "Shape: torch.Size([8, 8])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.queries.weight\n",
      "Shape: torch.Size([8, 8])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.fc_out.weight\n",
      "Shape: torch.Size([16, 16])\n",
      "Number of parameters: 256\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.fc_out.bias\n",
      "Shape: torch.Size([16])\n",
      "Number of parameters: 16\n",
      "--------------------------------------------------\n",
      "Parameter name: fc.weight\n",
      "Shape: torch.Size([2, 784])\n",
      "Number of parameters: 1568\n",
      "--------------------------------------------------\n",
      "Parameter name: fc.bias\n",
      "Shape: torch.Size([2])\n",
      "Number of parameters: 2\n",
      "--------------------------------------------------\n",
      "Total number of trainable parameters: 2034\n"
     ]
    }
   ],
   "source": [
    "# Print out the parameters and their shapes\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(f\"Number of parameters: {param.numel()}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 49, 16]             272\n",
      "     SelfAttention-2               [-1, 49, 16]               0\n",
      "            Linear-3                    [-1, 2]           1,570\n",
      "================================================================\n",
      "Total params: 1,842\n",
      "Trainable params: 1,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(49, 16))  # (sequence_length, embed_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def binary_accuracy(preds, y):\n",
    "#     \"\"\"\n",
    "#     Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "#     \"\"\"\n",
    "\n",
    "#     #round predictions to the closest integer\n",
    "#     rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
    "#     correct = (rounded_preds == y).float() #convert into float for division \n",
    "#     acc = correct.sum() / len(correct)\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your binary accuracy function\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48750001192092896\n",
      "Loss: 0.6940819025039673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:05<01:49,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete\n",
      "Accuracy: 0.737500011920929\n",
      "Loss: 0.6826744675636292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:08<01:10,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete\n",
      "Accuracy: 0.643750011920929\n",
      "Loss: 0.6723920106887817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:11<01:01,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete\n",
      "Accuracy: 0.6625000238418579\n",
      "Loss: 0.6625539064407349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:14<00:55,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete\n",
      "Accuracy: 0.6875\n",
      "Loss: 0.6527260541915894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:20<01:04,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete\n",
      "Accuracy: 0.7250000238418579\n",
      "Loss: 0.6429324150085449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:25<01:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 complete\n",
      "Accuracy: 0.7562500238418579\n",
      "Loss: 0.6333174109458923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:28<00:53,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 complete\n",
      "Accuracy: 0.768750011920929\n",
      "Loss: 0.6239303946495056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:32<00:46,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 complete\n",
      "Accuracy: 0.78125\n",
      "Loss: 0.6146809458732605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:36<00:44,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 complete\n",
      "Accuracy: 0.7875000238418579\n",
      "Loss: 0.6054513454437256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:41<00:43,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 complete\n",
      "Accuracy: 0.7875000238418579\n",
      "Loss: 0.5962273478507996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:47<00:43,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 complete\n",
      "Accuracy: 0.768750011920929\n",
      "Loss: 0.5870727300643921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:50<00:35,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 complete\n",
      "Accuracy: 0.768750011920929\n",
      "Loss: 0.5780654549598694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:54<00:29,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 complete\n",
      "Accuracy: 0.768750011920929\n",
      "Loss: 0.5692535638809204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:59<00:25,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 complete\n",
      "Accuracy: 0.7749999761581421\n",
      "Loss: 0.5606435537338257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:02<00:20,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 complete\n",
      "Accuracy: 0.7749999761581421\n",
      "Loss: 0.5522239804267883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:06<00:16,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 complete\n",
      "Accuracy: 0.768750011920929\n",
      "Loss: 0.5440053939819336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:10<00:11,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 complete\n",
      "Accuracy: 0.7749999761581421\n",
      "Loss: 0.5360281467437744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [01:13<00:07,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 complete\n",
      "Accuracy: 0.78125\n",
      "Loss: 0.528325617313385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [01:15<00:03,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 complete\n",
      "Accuracy: 0.78125\n",
      "Loss: 0.5208925604820251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:20<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for iepoch in tqdm(range(20)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Convert your X_train into tensor\n",
    "    X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(X_tensor)\n",
    "    \n",
    "    # Convert y_train to tensor and change labels from 1 to 0, and 7 to 1\n",
    "    label = torch.tensor(y_train, dtype=torch.long).clone()  # Ensure labels are LongTensor\n",
    "    for i in range(len(label)):\n",
    "        label[i] = 0 if label[i] == 1 else 1  # 1 -> 0, 7 -> 1\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(predictions, label)\n",
    "    \n",
    "    # Calculate binary accuracy (adjusted for your binary classification)\n",
    "    acc = binary_accuracy(predictions.argmax(dim=1), label)\n",
    "    \n",
    "    # Print accuracy and loss\n",
    "    print(f'Accuracy: {acc}')\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    \n",
    "    # Backward pass and optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {iepoch+1} complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8500000238418579\n",
      "\n",
      "Loss: 0.459276020526886\n",
      "\n",
      "AUROC: 0.9425000000000001\n",
      "\n",
      "Precision: 0.85\n",
      "\n",
      "Recall: 0.85\n",
      "\n",
      "F1 Score: 0.85\n",
      "\n",
      "AUPRC: 0.9367783708379683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "# Convert test data to tensor\n",
    "X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "predictions = model(X_tensor)\n",
    "\n",
    "# Convert y_train to tensor and change labels from 1 to 0, and 7 to 1\n",
    "label = torch.tensor(y_test, dtype=torch.long).clone()  # Ensure labels are LongTensor\n",
    "        \n",
    "# Reverse the labels (if needed)\n",
    "for i in range(len(label)):\n",
    "    if label[i] == 1:\n",
    "        label[i] = 0\n",
    "    else:\n",
    "        label[i] = 1\n",
    "\n",
    "# Calculate loss and accuracy\n",
    "# Compute loss\n",
    "loss = criterion(predictions, label)\n",
    "\n",
    "# Calculate binary accuracy (adjusted for your binary classification)\n",
    "acc = binary_accuracy(predictions.argmax(dim=1), label)\n",
    "\n",
    "# Convert predictions to probabilities using softmax\n",
    "probabilities = torch.softmax(predictions, dim=1)  # Shape: (batch_size, 2)\n",
    "\n",
    "# Extract probabilities for class 1 (positive class)\n",
    "positive_class_probs = probabilities[:, 1].detach().numpy()\n",
    "\n",
    "# Convert labels to numpy\n",
    "labels_np = label.numpy()\n",
    "\n",
    "# Calculate AUROC\n",
    "auroc = roc_auc_score(labels_np, positive_class_probs)\n",
    "\n",
    "# Binarize predictions for precision, recall, and F1 calculation\n",
    "binary_preds = np.where(positive_class_probs > 0.5, 1, 0)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels_np, binary_preds, average='binary')\n",
    "\n",
    "# Calculate AUPRC (Area Under the Precision-Recall Curve)\n",
    "auprc = average_precision_score(labels_np, positive_class_probs)\n",
    "\n",
    "# Print results\n",
    "print(f'\\nAccuracy: {acc}\\n')\n",
    "print(f'Loss: {loss}\\n')\n",
    "print(f'AUROC: {auroc}\\n')\n",
    "print(f'Precision: {precision}\\n')\n",
    "print(f'Recall: {recall}\\n')\n",
    "print(f'F1 Score: {f1}\\n')\n",
    "print(f'AUPRC: {auprc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
