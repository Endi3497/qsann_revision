{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 00:41:34.803116: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 00:41:34.819266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-20 00:41:34.838291: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-20 00:41:34.844164: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 00:41:34.859258: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 00:41:35.734739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 160\n",
      "Test set size: 40\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# MNIST 데이터 불러오기\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = mnist.load_data()\n",
    "\n",
    "# 데이터 정규화 (0-255 값을 0-1 사이로)\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test_full = X_test_full.astype('float32') / 255.0\n",
    "\n",
    "#torch.transform / normalize // imagenet mean sd \n",
    "\n",
    "# 숫자 1과 7만 선택하는 마스크 생성\n",
    "train_mask = np.isin(y_train_full, [1, 7])\n",
    "X_train, y_train = X_train_full[train_mask], y_train_full[train_mask]\n",
    "\n",
    "test_mask = np.isin(y_test_full, [1, 7])\n",
    "X_test, y_test = X_test_full[test_mask], y_test_full[test_mask]\n",
    "\n",
    "# 시드 고정 (예: 42로 고정)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2000개의 데이터를 무작위로 선택\n",
    "num_samples = 200\n",
    "indices = np.random.choice(len(X_train), num_samples, replace=False)\n",
    "X_sampled, y_sampled = X_train[indices], y_train[indices]\n",
    "\n",
    "# 2000개의 샘플에서 train/test 데이터 분할 (80% train, 20% test 비율로 나눔)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sampled, y_sampled, stratify=y_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 결과\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3144, Accuracy: 73.12%\n",
      "Epoch [2/10], Loss: 0.0595, Accuracy: 97.50%\n",
      "Epoch [3/10], Loss: 0.1071, Accuracy: 96.25%\n",
      "Epoch [4/10], Loss: 0.0036, Accuracy: 99.38%\n",
      "Epoch [5/10], Loss: 0.0012, Accuracy: 99.38%\n",
      "Epoch [6/10], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [7/10], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [8/10], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [9/10], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [10/10], Loss: 0.0002, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # 채널 차원 추가\n",
    "y_train = torch.tensor((y_train == 7).astype(np.float32))  # 1은 0으로, 7은 1로 변환\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor((y_test == 7).astype(np.float32))\n",
    "\n",
    "# 데이터셋과 데이터 로더 정의\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# CNN 모델 정의\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNNModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels = labels.unsqueeze(1)  # BCELoss에 맞추어 차원 맞추기\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy 계산\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {train_accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: conv1.weight\n",
      "Shape: torch.Size([32, 1, 3, 3])\n",
      "Number of parameters: 288\n",
      "--------------------------------------------------\n",
      "Parameter name: conv1.bias\n",
      "Shape: torch.Size([32])\n",
      "Number of parameters: 32\n",
      "--------------------------------------------------\n",
      "Parameter name: conv2.weight\n",
      "Shape: torch.Size([64, 32, 3, 3])\n",
      "Number of parameters: 18432\n",
      "--------------------------------------------------\n",
      "Parameter name: conv2.bias\n",
      "Shape: torch.Size([64])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: fc1.weight\n",
      "Shape: torch.Size([128, 3136])\n",
      "Number of parameters: 401408\n",
      "--------------------------------------------------\n",
      "Parameter name: fc1.bias\n",
      "Shape: torch.Size([128])\n",
      "Number of parameters: 128\n",
      "--------------------------------------------------\n",
      "Parameter name: fc2.weight\n",
      "Shape: torch.Size([1, 128])\n",
      "Number of parameters: 128\n",
      "--------------------------------------------------\n",
      "Parameter name: fc2.bias\n",
      "Shape: torch.Size([1])\n",
      "Number of parameters: 1\n",
      "--------------------------------------------------\n",
      "Total number of trainable parameters: 420481\n"
     ]
    }
   ],
   "source": [
    "# Print out the parameters and their shapes\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(f\"Number of parameters: {param.numel()}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.50%\n",
      "AUROC: 1.0000\n",
      "Precision: 0.9524\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9756\n",
      "AUPRC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 테스트 평가\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.unsqueeze(1)\n",
    "        outputs = model(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "# 리스트를 numpy 배열로 변환\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# 이진 분류 결과 계산\n",
    "test_accuracy = accuracy_score(all_labels, all_preds > 0.5)\n",
    "test_roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds > 0.5)\n",
    "test_recall = recall_score(all_labels, all_preds > 0.5)\n",
    "test_f1 = f1_score(all_labels, all_preds > 0.5)\n",
    "test_auprc = average_precision_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"AUROC: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"AUPRC: {test_auprc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
