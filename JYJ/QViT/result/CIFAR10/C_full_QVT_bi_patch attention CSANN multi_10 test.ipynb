{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 21:13:57.350266: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 21:13:57.371772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-05 21:13:57.397353: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-05 21:13:57.405250: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 21:13:57.423876: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 21:13:58.457515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 320\n",
      "Test set size: 80\n",
      "Sampled train labels: [0. 1.]\n",
      "Sampled test labels: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# CIFAR-10 데이터 불러오기\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = cifar10.load_data()\n",
    "\n",
    "# 데이터 정규화 (0-255 값을 0-1 사이로)\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test_full = X_test_full.astype('float32') / 255.0\n",
    "\n",
    "# RGB -> Grayscale 변환\n",
    "# 공식: 0.299*R + 0.587*G + 0.114*B\n",
    "X_train_gray = np.dot(X_train_full[...,:3], [0.299, 0.587, 0.114])\n",
    "X_test_gray = np.dot(X_test_full[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "# 원하는 두 개의 클래스만 선택 (예: 클래스 0과 1)\n",
    "selected_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# 클래스 0과 1에 해당하는 데이터만 선택 (train set)\n",
    "train_mask = np.isin(y_train_full, selected_classes)\n",
    "X_train_filtered = X_train_gray[train_mask.squeeze()]\n",
    "y_train_filtered = y_train_full[train_mask.squeeze()]\n",
    "\n",
    "# # 클래스 0과 1에 해당하는 데이터만 선택 (test set)\n",
    "# test_mask = np.isin(y_test_full, selected_classes)\n",
    "# X_test_filtered = X_test_gray[test_mask.squeeze()]\n",
    "# y_test_filtered = y_test_full[test_mask.squeeze()]\n",
    "\n",
    "\n",
    "# 시드 고정\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2000개의 데이터를 무작위로 선택\n",
    "num_samples = 400\n",
    "indices = np.random.choice(len(X_train_filtered), num_samples, replace=False)\n",
    "X_sampled, y_sampled = X_train_filtered[indices], y_train_filtered[indices]\n",
    "\n",
    "# 2000개의 샘플에서 train/test 데이터 분할 (80% train, 20% test 비율로 나눔)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sampled, y_sampled, stratify=y_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train = y_train.squeeze(1)\n",
    "y_test = y_test.squeeze(1)\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Sampled train labels: {np.unique(y_train)}\")\n",
    "print(f\"Sampled test labels: {np.unique(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 32, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 크기로 겹치지 않게 패치로 나누는 함수\n",
    "def split_into_non_overlapping_patches(image, patch_size=(4, 4)):\n",
    "    patches = []\n",
    "    for i in range(0, image.shape[0], patch_size[0]):\n",
    "        for j in range(0, image.shape[1], patch_size[1]):\n",
    "            patch = image[i:i+patch_size[0], j:j+patch_size[1]].flatten()\n",
    "            patches.append(patch)\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지를 2x2 겹치지 않는 패치로 나누기\n",
    "X_train = np.array([split_into_non_overlapping_patches(img) for img in X_train])\n",
    "X_test = np.array([split_into_non_overlapping_patches(img) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 2880, 1.0: 320}\n"
     ]
    }
   ],
   "source": [
    "# y_train이 numpy 배열일 경우\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 720, 1.0: 80}\n"
     ]
    }
   ],
   "source": [
    "# y_train이 numpy 배열일 경우\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 64, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Self-Attention and Binary Classifier from previous code\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert self.head_dim * heads == embed_size, \"Embedding size must be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask=None):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        # Split embedding into multiple heads\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "# Classifier model\n",
    "class SimpleSelfAttentionClassifier(nn.Module):\n",
    "    def __init__(self, embed_size=16, heads=2, num_classes=10):\n",
    "        super(SimpleSelfAttentionClassifier, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.fc = nn.Linear(embed_size * 64, num_classes)  # 49 is the sequence length in X_train\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output = self.attention(x, x, x)\n",
    "        attention_output = attention_output.flatten(start_dim=1)  # Flatten to feed into classifier\n",
    "        out = self.fc(attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, loss, optimizer\n",
    "model = SimpleSelfAttentionClassifier(embed_size=16, heads=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: attention.values.weight\n",
      "Shape: torch.Size([8, 8])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.keys.weight\n",
      "Shape: torch.Size([8, 8])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.queries.weight\n",
      "Shape: torch.Size([8, 8])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.fc_out.weight\n",
      "Shape: torch.Size([16, 16])\n",
      "Number of parameters: 256\n",
      "--------------------------------------------------\n",
      "Parameter name: attention.fc_out.bias\n",
      "Shape: torch.Size([16])\n",
      "Number of parameters: 16\n",
      "--------------------------------------------------\n",
      "Parameter name: fc.weight\n",
      "Shape: torch.Size([10, 1024])\n",
      "Number of parameters: 10240\n",
      "--------------------------------------------------\n",
      "Parameter name: fc.bias\n",
      "Shape: torch.Size([10])\n",
      "Number of parameters: 10\n",
      "--------------------------------------------------\n",
      "Total number of trainable parameters: 10714\n"
     ]
    }
   ],
   "source": [
    "# Print out the parameters and their shapes\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(f\"Number of parameters: {param.numel()}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 64, 16]             272\n",
      "     SelfAttention-2               [-1, 64, 16]               0\n",
      "            Linear-3                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 10,522\n",
      "Trainable params: 10,522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(64, 16))  # (sequence_length, embed_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def binary_accuracy(preds, y):\n",
    "#     \"\"\"\n",
    "#     Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "#     \"\"\"\n",
    "\n",
    "#     #round predictions to the closest integer\n",
    "#     rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
    "#     correct = (rounded_preds == y).float() #convert into float for division \n",
    "#     acc = correct.sum() / len(correct)\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    pred_soft = torch.log_softmax(preds, dim=1)\n",
    "    _, pred_index = torch.max(pred_soft, dim=1)\n",
    "    print(pred_index)\n",
    "    y = [int(w.argmax()) for w in y]\n",
    "    y = torch.tensor(y, dtype=float)\n",
    "    print(y)\n",
    "    correct_pred = (pred_index == y).float()\n",
    "    #round predictions to the closest integer\n",
    "    \n",
    "    acc = correct_pred.sum()/len(correct_pred)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:00<00:00, 43.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
      "        1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3,\n",
      "        1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 3, 1, 1, 1, 3, 3, 3,\n",
      "        3, 1, 3, 3, 1, 1, 3, 1, 1, 1, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 1, 3, 1, 3,\n",
      "        1, 1, 1, 3, 3, 1, 1, 1, 3, 1, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 3, 1, 3, 3,\n",
      "        3, 3, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 1, 1, 1,\n",
      "        3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 1,\n",
      "        3, 1, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 1, 3, 3, 3, 1, 1, 1, 3, 1, 3,\n",
      "        3, 3, 3, 1, 1, 3, 1, 1, 3, 3, 3, 1, 3, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 1,\n",
      "        3, 3, 1, 3, 1, 1, 3, 1, 3, 1, 3, 3, 1, 3, 1, 3, 3, 3, 1, 1, 3, 1, 1, 1,\n",
      "        3, 1, 1, 1, 3, 1, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 3, 1, 1, 3, 1, 3, 1, 1,\n",
      "        3, 1, 3, 1, 3, 1, 1, 3, 3, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 1, 3, 1,\n",
      "        1, 3, 1, 1, 1, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1,\n",
      "        3, 3, 3, 3, 1, 3, 1, 3])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1063)\n",
      "\n",
      "tensor(2.3114, grad_fn=<DivBackward1>)\n",
      "tensor([8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 7, 8, 8, 8, 7, 8, 8, 7,\n",
      "        8, 8, 7, 8, 7, 8, 7, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        7, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8,\n",
      "        8, 7, 8, 8, 7, 7, 8, 7, 7, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 7, 7, 8, 7, 8,\n",
      "        7, 8, 7, 8, 8, 7, 7, 7, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 7, 8, 8, 7, 8, 8,\n",
      "        8, 8, 8, 8, 7, 7, 8, 7, 7, 8, 7, 7, 7, 7, 8, 7, 8, 8, 8, 8, 7, 8, 7, 8,\n",
      "        8, 8, 7, 7, 7, 8, 8, 8, 8, 7, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 7, 8, 8, 7,\n",
      "        8, 8, 8, 8, 8, 8, 8, 7, 8, 7, 7, 7, 8, 8, 7, 8, 8, 8, 8, 8, 7, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 7, 8, 8, 8, 8, 7,\n",
      "        8, 8, 8, 8, 8, 7, 8, 8, 8, 7, 8, 8, 7, 8, 7, 8, 8, 8, 7, 7, 8, 7, 7, 8,\n",
      "        8, 8, 7, 7, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 8, 7, 8, 7, 7,\n",
      "        8, 8, 8, 7, 8, 7, 7, 8, 8, 8, 7, 7, 8, 8, 8, 8, 7, 7, 8, 8, 8, 7, 8, 8,\n",
      "        7, 8, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1187)\n",
      "\n",
      "tensor(2.3003, grad_fn=<DivBackward1>)\n",
      "tensor([4, 4, 7, 4, 7, 7, 4, 4, 7, 7, 7, 7, 4, 4, 4, 4, 7, 7, 7, 7, 7, 7, 4, 7,\n",
      "        7, 7, 7, 4, 7, 4, 7, 7, 4, 4, 4, 7, 4, 7, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4,\n",
      "        7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 4, 7, 4, 4, 4, 4, 4, 7, 4, 4, 4,\n",
      "        7, 7, 4, 4, 7, 7, 4, 7, 4, 7, 4, 4, 7, 4, 4, 7, 4, 4, 4, 7, 7, 4, 7, 4,\n",
      "        7, 7, 7, 4, 4, 7, 7, 7, 4, 7, 4, 7, 7, 4, 7, 4, 4, 4, 7, 7, 4, 7, 4, 4,\n",
      "        4, 4, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 7, 7, 4, 7, 4, 4, 4, 4, 7, 7, 7, 4,\n",
      "        4, 4, 7, 7, 7, 7, 4, 4, 4, 7, 4, 4, 4, 7, 7, 4, 4, 4, 4, 4, 7, 7, 4, 7,\n",
      "        4, 7, 7, 4, 7, 4, 4, 7, 7, 7, 7, 7, 4, 4, 7, 4, 4, 4, 4, 7, 7, 4, 7, 4,\n",
      "        4, 7, 4, 7, 7, 4, 7, 7, 4, 4, 4, 7, 4, 7, 7, 7, 4, 4, 7, 7, 7, 4, 4, 7,\n",
      "        4, 4, 7, 4, 7, 7, 7, 7, 4, 7, 4, 4, 7, 4, 7, 4, 4, 7, 7, 7, 4, 7, 7, 4,\n",
      "        4, 7, 7, 7, 4, 7, 4, 4, 4, 4, 7, 4, 7, 4, 4, 4, 4, 4, 7, 4, 7, 4, 7, 7,\n",
      "        4, 7, 7, 7, 4, 7, 7, 4, 4, 4, 7, 7, 7, 4, 4, 4, 7, 7, 7, 4, 4, 7, 4, 4,\n",
      "        7, 4, 7, 7, 7, 4, 4, 4, 7, 7, 4, 7, 4, 4, 4, 7, 4, 4, 4, 4, 7, 4, 7, 4,\n",
      "        4, 4, 4, 4, 7, 4, 7, 4])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1063)\n",
      "\n",
      "tensor(2.2939, grad_fn=<DivBackward1>)\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1156)\n",
      "\n",
      "tensor(2.2943, grad_fn=<DivBackward1>)\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 9, 4, 4, 9, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 9, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 9, 9, 4, 4, 4, 4, 9, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 9, 4, 9, 4, 4, 4, 9, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 9, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1125)\n",
      "\n",
      "tensor(2.2907, grad_fn=<DivBackward1>)\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 9, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9,\n",
      "        4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 9, 9,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 9, 4, 4, 4, 4, 9, 4, 4, 9, 1, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 9, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 9, 9, 4, 4, 4, 9, 9, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 9, 9, 4, 9, 4, 9, 4, 4, 4, 9, 4, 4,\n",
      "        4, 4, 9, 4, 4, 4, 4, 4, 4, 9, 9, 4, 9, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 9, 1, 4, 4, 4, 4, 4,\n",
      "        9, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 9, 4, 4, 9, 9, 9, 4, 4, 9, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4,\n",
      "        1, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1281)\n",
      "\n",
      "tensor(2.2843, grad_fn=<DivBackward1>)\n",
      "tensor([4, 8, 1, 8, 1, 1, 9, 8, 1, 1, 1, 1, 4, 8, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1,\n",
      "        4, 1, 1, 8, 1, 8, 1, 1, 8, 8, 4, 1, 8, 1, 1, 4, 4, 1, 8, 4, 4, 4, 4, 8,\n",
      "        1, 1, 4, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 4, 4, 8, 4, 1, 1, 4, 8, 8,\n",
      "        4, 1, 4, 4, 1, 1, 4, 1, 1, 1, 4, 8, 1, 8, 4, 1, 8, 4, 8, 1, 1, 8, 1, 4,\n",
      "        1, 1, 1, 4, 4, 1, 1, 1, 8, 1, 8, 4, 1, 8, 1, 4, 4, 8, 1, 1, 8, 1, 4, 4,\n",
      "        4, 8, 1, 4, 1, 4, 8, 1, 1, 8, 1, 1, 1, 1, 8, 1, 8, 4, 8, 8, 1, 1, 1, 4,\n",
      "        8, 8, 1, 1, 1, 1, 8, 8, 4, 1, 4, 8, 8, 1, 1, 8, 4, 4, 8, 8, 1, 4, 1, 1,\n",
      "        4, 1, 8, 4, 1, 8, 8, 1, 4, 1, 1, 1, 8, 8, 1, 8, 8, 8, 4, 1, 1, 8, 1, 8,\n",
      "        8, 4, 8, 1, 1, 4, 1, 1, 8, 8, 8, 1, 8, 1, 1, 1, 8, 8, 1, 1, 1, 4, 4, 1,\n",
      "        4, 8, 1, 8, 1, 1, 4, 4, 4, 1, 4, 8, 1, 8, 1, 8, 8, 8, 1, 1, 4, 1, 1, 4,\n",
      "        8, 1, 1, 1, 4, 1, 8, 8, 1, 4, 1, 8, 1, 4, 8, 8, 8, 4, 1, 8, 1, 8, 1, 1,\n",
      "        8, 1, 1, 1, 8, 1, 1, 8, 8, 8, 1, 1, 1, 4, 8, 4, 1, 1, 1, 4, 8, 1, 4, 4,\n",
      "        1, 8, 1, 1, 1, 4, 4, 8, 1, 4, 8, 1, 4, 8, 4, 1, 8, 4, 1, 4, 1, 4, 1, 4,\n",
      "        8, 4, 8, 8, 4, 8, 1, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1344)\n",
      "\n",
      "tensor(2.2799, grad_fn=<DivBackward1>)\n",
      "tensor([8, 8, 1, 8, 1, 1, 8, 8, 1, 1, 1, 1, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1,\n",
      "        1, 1, 1, 8, 1, 8, 1, 1, 8, 8, 1, 1, 8, 1, 1, 1, 1, 1, 8, 8, 1, 8, 1, 8,\n",
      "        1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 8, 1, 8, 1, 1, 1, 8, 8, 8,\n",
      "        8, 1, 8, 1, 1, 1, 8, 1, 1, 1, 8, 8, 1, 8, 8, 1, 8, 8, 8, 1, 1, 8, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 8, 1, 1, 8, 1, 8, 1, 8, 1, 1, 8, 1, 1, 8,\n",
      "        8, 8, 1, 8, 1, 1, 8, 1, 1, 8, 1, 1, 1, 1, 8, 1, 8, 1, 8, 8, 1, 1, 1, 1,\n",
      "        8, 8, 1, 1, 1, 1, 8, 8, 1, 1, 1, 8, 8, 1, 1, 8, 1, 8, 8, 8, 1, 1, 1, 1,\n",
      "        1, 1, 8, 1, 1, 8, 8, 1, 8, 1, 1, 1, 8, 8, 1, 8, 8, 8, 1, 1, 1, 8, 1, 8,\n",
      "        8, 1, 8, 1, 1, 1, 1, 1, 8, 8, 8, 1, 8, 1, 1, 1, 8, 8, 1, 1, 1, 8, 8, 1,\n",
      "        1, 8, 1, 8, 1, 1, 1, 1, 1, 1, 1, 8, 1, 8, 1, 8, 8, 8, 1, 1, 8, 1, 1, 1,\n",
      "        8, 1, 1, 1, 8, 1, 8, 8, 1, 8, 1, 8, 1, 8, 8, 8, 8, 1, 1, 8, 1, 8, 1, 1,\n",
      "        8, 1, 1, 1, 8, 1, 1, 8, 8, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 8, 8, 1, 1, 1,\n",
      "        1, 8, 1, 1, 1, 8, 8, 8, 1, 1, 8, 1, 8, 8, 1, 1, 8, 8, 1, 1, 1, 1, 1, 1,\n",
      "        8, 8, 8, 8, 1, 8, 1, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1281)\n",
      "\n",
      "tensor(2.2775, grad_fn=<DivBackward1>)\n",
      "tensor([8, 8, 1, 8, 1, 1, 8, 8, 1, 1, 1, 1, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 8, 1,\n",
      "        1, 1, 1, 8, 1, 8, 1, 1, 8, 8, 1, 1, 8, 1, 1, 1, 8, 1, 8, 8, 1, 8, 8, 8,\n",
      "        1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 8, 1, 8, 1, 1, 1, 8, 8, 8,\n",
      "        8, 1, 8, 8, 1, 1, 8, 1, 1, 1, 8, 8, 1, 8, 8, 1, 8, 8, 8, 1, 1, 8, 1, 1,\n",
      "        1, 1, 1, 1, 8, 1, 1, 1, 8, 1, 8, 1, 1, 8, 1, 8, 8, 8, 1, 8, 8, 1, 1, 8,\n",
      "        8, 8, 1, 8, 1, 1, 8, 1, 1, 8, 1, 1, 1, 1, 8, 1, 8, 1, 8, 8, 1, 1, 1, 1,\n",
      "        8, 8, 1, 1, 1, 1, 8, 8, 8, 1, 8, 8, 8, 1, 1, 8, 8, 8, 8, 8, 1, 1, 1, 1,\n",
      "        8, 1, 8, 1, 1, 8, 8, 1, 8, 1, 1, 1, 8, 8, 1, 8, 8, 8, 1, 1, 1, 8, 1, 8,\n",
      "        8, 8, 8, 1, 1, 8, 1, 1, 8, 8, 8, 1, 8, 1, 1, 1, 8, 8, 1, 8, 1, 8, 8, 1,\n",
      "        8, 8, 1, 8, 1, 1, 8, 1, 8, 1, 8, 8, 1, 8, 1, 8, 8, 8, 1, 1, 8, 1, 1, 1,\n",
      "        8, 1, 1, 1, 8, 1, 8, 8, 8, 8, 1, 8, 1, 8, 8, 8, 8, 1, 1, 8, 1, 8, 1, 1,\n",
      "        8, 1, 8, 1, 8, 1, 1, 8, 8, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 8, 8, 1, 8, 1,\n",
      "        1, 8, 1, 1, 1, 8, 8, 8, 1, 8, 8, 1, 8, 8, 1, 1, 8, 8, 1, 1, 1, 1, 1, 1,\n",
      "        8, 8, 8, 8, 1, 8, 1, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1281)\n",
      "\n",
      "tensor(2.2753, grad_fn=<DivBackward1>)\n",
      "tensor([8, 8, 7, 8, 7, 7, 8, 8, 1, 7, 7, 7, 8, 8, 7, 7, 7, 7, 7, 7, 1, 7, 8, 7,\n",
      "        7, 7, 7, 8, 7, 8, 1, 7, 8, 8, 7, 7, 8, 7, 7, 7, 8, 7, 8, 8, 7, 8, 7, 8,\n",
      "        7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 8, 7, 8, 7, 8, 7, 7, 7, 8, 8, 8,\n",
      "        8, 7, 8, 8, 7, 7, 8, 1, 7, 7, 8, 8, 7, 8, 8, 7, 8, 8, 8, 7, 7, 8, 7, 7,\n",
      "        7, 7, 7, 7, 8, 7, 7, 7, 8, 7, 8, 7, 7, 8, 7, 8, 7, 8, 7, 8, 8, 7, 7, 8,\n",
      "        8, 8, 7, 8, 7, 7, 8, 7, 7, 8, 7, 7, 7, 7, 8, 7, 8, 7, 8, 8, 7, 7, 7, 7,\n",
      "        8, 8, 7, 7, 7, 7, 8, 8, 7, 7, 7, 8, 8, 1, 7, 8, 7, 8, 8, 8, 7, 7, 7, 7,\n",
      "        7, 7, 8, 7, 7, 8, 8, 7, 8, 7, 7, 7, 8, 8, 7, 8, 8, 8, 7, 7, 7, 8, 7, 8,\n",
      "        8, 8, 8, 7, 7, 8, 7, 7, 8, 8, 8, 7, 8, 1, 7, 7, 8, 8, 7, 8, 7, 8, 8, 7,\n",
      "        8, 8, 7, 8, 7, 7, 7, 7, 8, 7, 8, 8, 7, 8, 7, 8, 8, 8, 6, 7, 8, 7, 7, 7,\n",
      "        8, 7, 7, 7, 8, 6, 8, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 7, 7, 8, 7, 8, 7, 7,\n",
      "        8, 7, 7, 7, 8, 7, 7, 8, 8, 8, 7, 7, 7, 7, 8, 7, 7, 7, 7, 8, 8, 7, 7, 7,\n",
      "        6, 8, 7, 7, 7, 8, 8, 8, 7, 7, 8, 7, 8, 8, 7, 1, 8, 8, 7, 7, 6, 7, 1, 7,\n",
      "        8, 8, 8, 8, 7, 8, 7, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1219)\n",
      "\n",
      "tensor(2.2727, grad_fn=<DivBackward1>)\n",
      "tensor([5, 9, 7, 8, 7, 7, 9, 9, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 8, 7, 8, 7, 7, 8, 9, 7, 7, 8, 7, 7, 7, 7, 7, 8, 9, 7, 9, 7, 9,\n",
      "        7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 8, 7, 7, 7, 7, 9, 9,\n",
      "        7, 7, 9, 7, 7, 7, 9, 7, 7, 7, 7, 8, 7, 9, 7, 7, 8, 7, 9, 7, 7, 9, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 9, 7, 7, 9, 7, 8, 7, 9, 7, 7, 8, 7, 7, 7,\n",
      "        7, 8, 7, 7, 7, 7, 8, 7, 7, 9, 7, 7, 7, 7, 9, 7, 9, 7, 9, 8, 7, 7, 7, 7,\n",
      "        9, 9, 7, 7, 7, 7, 9, 8, 7, 7, 7, 8, 9, 7, 7, 9, 7, 7, 8, 9, 7, 7, 7, 7,\n",
      "        7, 7, 8, 7, 7, 9, 9, 7, 7, 7, 7, 7, 8, 9, 7, 9, 9, 9, 7, 7, 7, 9, 7, 8,\n",
      "        8, 7, 8, 7, 7, 7, 7, 7, 8, 9, 9, 7, 8, 7, 7, 7, 8, 8, 7, 7, 7, 7, 8, 7,\n",
      "        7, 9, 7, 9, 7, 7, 7, 7, 7, 7, 9, 8, 7, 8, 7, 8, 8, 9, 7, 7, 7, 7, 7, 7,\n",
      "        9, 7, 7, 7, 7, 6, 9, 9, 7, 7, 7, 9, 7, 7, 9, 8, 9, 7, 7, 9, 7, 8, 7, 7,\n",
      "        8, 7, 7, 7, 8, 7, 7, 8, 8, 9, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 8, 7, 7, 7,\n",
      "        6, 8, 7, 7, 7, 7, 5, 9, 7, 7, 8, 7, 7, 8, 7, 7, 8, 7, 7, 7, 6, 7, 7, 7,\n",
      "        9, 7, 9, 8, 7, 9, 7, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1187)\n",
      "\n",
      "tensor(2.2702, grad_fn=<DivBackward1>)\n",
      "tensor([5, 9, 7, 9, 7, 7, 9, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7,\n",
      "        7, 7, 7, 9, 7, 9, 7, 7, 9, 9, 7, 7, 9, 7, 7, 7, 7, 7, 9, 9, 7, 9, 7, 9,\n",
      "        7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 9, 7, 7, 7, 9, 9, 9,\n",
      "        7, 7, 9, 7, 7, 7, 9, 7, 7, 7, 5, 9, 7, 9, 9, 7, 9, 7, 9, 7, 7, 9, 7, 7,\n",
      "        7, 7, 7, 7, 9, 7, 7, 7, 9, 7, 9, 7, 7, 9, 7, 9, 7, 9, 7, 7, 9, 7, 7, 5,\n",
      "        9, 9, 7, 9, 7, 7, 5, 7, 7, 9, 7, 7, 7, 7, 9, 7, 9, 7, 9, 5, 7, 7, 7, 7,\n",
      "        9, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7, 9, 9, 7, 7, 9, 7, 5, 9, 9, 7, 7, 7, 7,\n",
      "        7, 7, 5, 7, 7, 9, 9, 7, 5, 7, 7, 7, 9, 9, 7, 9, 9, 9, 7, 7, 7, 9, 7, 9,\n",
      "        5, 7, 9, 7, 7, 7, 7, 7, 9, 9, 9, 7, 9, 7, 7, 7, 9, 9, 7, 7, 7, 9, 9, 7,\n",
      "        7, 9, 7, 9, 7, 7, 9, 7, 7, 7, 9, 9, 7, 9, 7, 9, 9, 9, 7, 7, 5, 7, 7, 7,\n",
      "        9, 7, 7, 7, 9, 6, 9, 9, 7, 5, 7, 9, 7, 9, 9, 9, 9, 7, 7, 9, 7, 9, 7, 7,\n",
      "        9, 7, 7, 7, 9, 7, 7, 9, 9, 9, 7, 7, 7, 7, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7,\n",
      "        6, 9, 7, 7, 7, 9, 5, 9, 7, 9, 9, 7, 7, 9, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7,\n",
      "        9, 9, 9, 9, 7, 9, 7, 9])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1312)\n",
      "\n",
      "tensor(2.2681, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 59.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 9, 7, 9, 7, 7, 9, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7,\n",
      "        7, 7, 7, 9, 7, 9, 7, 7, 9, 9, 7, 7, 9, 7, 7, 7, 7, 7, 9, 9, 7, 9, 7, 9,\n",
      "        7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 9, 7, 9, 7, 9, 7, 7, 7, 9, 9, 9,\n",
      "        9, 7, 9, 7, 7, 7, 9, 7, 7, 7, 5, 9, 7, 9, 9, 7, 9, 9, 9, 7, 7, 9, 7, 7,\n",
      "        7, 7, 7, 7, 9, 7, 7, 7, 9, 7, 9, 7, 7, 9, 7, 9, 7, 9, 7, 7, 9, 7, 7, 5,\n",
      "        9, 9, 7, 9, 7, 7, 5, 7, 7, 9, 7, 7, 7, 7, 9, 7, 9, 7, 9, 5, 7, 7, 7, 7,\n",
      "        9, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7, 9, 9, 7, 7, 9, 7, 5, 9, 9, 7, 7, 7, 7,\n",
      "        7, 7, 5, 7, 7, 9, 9, 7, 5, 7, 7, 7, 9, 9, 7, 9, 9, 9, 7, 7, 7, 9, 7, 9,\n",
      "        9, 9, 9, 7, 7, 7, 7, 7, 9, 9, 9, 7, 9, 7, 7, 7, 9, 9, 7, 7, 7, 9, 9, 7,\n",
      "        7, 9, 7, 9, 7, 7, 9, 7, 9, 7, 9, 9, 7, 9, 7, 9, 9, 9, 7, 7, 5, 7, 7, 7,\n",
      "        9, 7, 7, 7, 9, 6, 9, 9, 5, 5, 7, 9, 7, 9, 9, 9, 9, 7, 7, 9, 7, 9, 7, 7,\n",
      "        9, 7, 7, 7, 9, 7, 7, 9, 9, 9, 7, 7, 7, 7, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7,\n",
      "        6, 9, 7, 7, 7, 9, 5, 9, 7, 9, 9, 7, 7, 9, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7,\n",
      "        9, 9, 9, 9, 7, 9, 7, 9])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1312)\n",
      "\n",
      "tensor(2.2659, grad_fn=<DivBackward1>)\n",
      "tensor([5, 9, 7, 9, 7, 7, 9, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7,\n",
      "        7, 7, 7, 9, 7, 9, 7, 7, 9, 9, 7, 7, 9, 7, 7, 7, 7, 7, 9, 9, 7, 9, 7, 9,\n",
      "        7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 9, 7, 9, 7, 9, 7, 7, 7, 9, 9, 9,\n",
      "        9, 7, 9, 7, 7, 7, 9, 7, 7, 7, 5, 9, 7, 9, 9, 7, 9, 9, 9, 7, 7, 9, 7, 7,\n",
      "        7, 7, 7, 7, 9, 7, 7, 7, 9, 7, 9, 7, 7, 9, 7, 9, 7, 9, 7, 7, 9, 7, 7, 5,\n",
      "        9, 9, 7, 9, 7, 7, 9, 7, 7, 9, 7, 7, 7, 7, 9, 7, 9, 7, 9, 5, 7, 7, 7, 7,\n",
      "        9, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7, 9, 9, 7, 7, 9, 7, 5, 9, 9, 7, 7, 7, 7,\n",
      "        7, 7, 5, 7, 7, 9, 9, 7, 5, 7, 7, 7, 9, 9, 7, 9, 9, 9, 7, 7, 7, 9, 7, 9,\n",
      "        9, 7, 9, 7, 7, 7, 7, 7, 9, 9, 9, 7, 9, 7, 7, 7, 9, 9, 7, 7, 7, 9, 9, 7,\n",
      "        7, 9, 7, 9, 7, 7, 9, 7, 7, 7, 9, 9, 7, 9, 7, 9, 9, 9, 7, 7, 5, 7, 7, 7,\n",
      "        9, 7, 7, 7, 9, 6, 9, 9, 7, 5, 7, 9, 7, 9, 9, 9, 9, 7, 7, 9, 7, 9, 7, 7,\n",
      "        9, 7, 7, 7, 9, 7, 7, 9, 9, 9, 7, 7, 7, 7, 9, 7, 7, 7, 7, 9, 9, 7, 7, 7,\n",
      "        6, 9, 7, 7, 7, 9, 5, 9, 7, 9, 9, 7, 7, 9, 7, 7, 9, 9, 7, 7, 6, 7, 7, 7,\n",
      "        9, 9, 9, 9, 7, 9, 7, 9])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1312)\n",
      "\n",
      "tensor(2.2634, grad_fn=<DivBackward1>)\n",
      "tensor([4, 9, 4, 9, 4, 7, 9, 9, 7, 4, 4, 7, 4, 9, 4, 4, 7, 4, 4, 4, 7, 4, 4, 7,\n",
      "        4, 4, 7, 9, 4, 9, 7, 7, 9, 9, 4, 4, 9, 7, 4, 4, 4, 4, 9, 4, 4, 4, 4, 9,\n",
      "        7, 4, 4, 4, 4, 7, 9, 4, 4, 4, 4, 7, 7, 9, 4, 4, 4, 9, 4, 4, 7, 4, 9, 9,\n",
      "        4, 7, 4, 4, 7, 7, 9, 7, 4, 7, 4, 9, 7, 9, 4, 4, 9, 4, 9, 7, 7, 9, 6, 4,\n",
      "        7, 4, 7, 4, 4, 7, 7, 7, 9, 4, 9, 7, 7, 9, 4, 4, 4, 9, 7, 4, 9, 7, 4, 4,\n",
      "        4, 9, 4, 4, 7, 7, 4, 7, 7, 9, 7, 7, 7, 4, 9, 7, 9, 4, 9, 5, 7, 7, 7, 4,\n",
      "        9, 9, 4, 7, 7, 4, 9, 9, 4, 7, 4, 9, 9, 7, 7, 9, 4, 4, 9, 9, 7, 4, 4, 7,\n",
      "        4, 4, 5, 4, 4, 9, 9, 7, 4, 7, 7, 7, 9, 9, 7, 9, 9, 9, 4, 4, 7, 9, 4, 9,\n",
      "        9, 4, 9, 4, 4, 4, 4, 4, 9, 9, 9, 4, 9, 7, 4, 4, 9, 9, 7, 4, 7, 4, 4, 7,\n",
      "        4, 9, 4, 9, 4, 4, 4, 4, 4, 7, 4, 9, 7, 9, 7, 9, 9, 9, 6, 7, 4, 7, 7, 4,\n",
      "        9, 4, 7, 4, 4, 6, 9, 9, 4, 4, 4, 9, 4, 4, 9, 9, 9, 4, 7, 9, 7, 9, 7, 4,\n",
      "        9, 4, 4, 7, 9, 7, 7, 4, 9, 9, 7, 4, 4, 4, 9, 4, 7, 7, 4, 4, 9, 7, 4, 4,\n",
      "        6, 9, 7, 7, 7, 4, 4, 9, 4, 9, 9, 4, 4, 9, 4, 4, 9, 4, 4, 4, 6, 4, 4, 4,\n",
      "        9, 4, 9, 9, 4, 9, 4, 9])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1344)\n",
      "\n",
      "tensor(2.2611, grad_fn=<DivBackward1>)\n",
      "tensor([4, 8, 4, 8, 4, 4, 9, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 8, 4, 8, 7, 4, 9, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9,\n",
      "        4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 8, 4, 4, 4, 4, 9, 9,\n",
      "        4, 4, 4, 4, 7, 4, 4, 4, 4, 7, 4, 8, 6, 9, 4, 4, 8, 4, 9, 4, 7, 9, 6, 4,\n",
      "        7, 4, 4, 4, 4, 7, 4, 4, 8, 4, 9, 4, 7, 9, 4, 4, 4, 8, 4, 4, 8, 4, 4, 4,\n",
      "        4, 8, 4, 4, 7, 4, 4, 4, 4, 9, 4, 4, 4, 4, 9, 4, 9, 4, 9, 4, 7, 4, 7, 4,\n",
      "        9, 9, 4, 4, 4, 4, 9, 9, 4, 4, 4, 8, 9, 4, 4, 9, 4, 4, 8, 9, 7, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 9, 9, 7, 4, 4, 4, 4, 9, 9, 7, 9, 9, 9, 4, 4, 4, 9, 4, 4,\n",
      "        4, 4, 9, 4, 4, 4, 4, 4, 8, 9, 9, 4, 8, 7, 4, 4, 8, 8, 6, 4, 4, 4, 4, 4,\n",
      "        4, 9, 4, 9, 4, 4, 4, 4, 4, 4, 4, 9, 7, 8, 4, 8, 8, 9, 6, 4, 4, 4, 7, 4,\n",
      "        9, 4, 4, 4, 4, 6, 8, 9, 4, 4, 4, 9, 4, 4, 9, 8, 9, 4, 4, 9, 4, 8, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 8, 9, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 8, 4, 4, 4,\n",
      "        6, 4, 4, 7, 7, 4, 4, 9, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4, 6, 4, 4, 4,\n",
      "        8, 4, 9, 4, 4, 4, 4, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1375)\n",
      "\n",
      "tensor(2.2594, grad_fn=<DivBackward1>)\n",
      "tensor([4, 8, 4, 8, 4, 4, 9, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 8, 4, 8, 4, 4, 8, 8, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8,\n",
      "        4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 8, 4, 4, 4, 4, 8, 8,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 6, 9, 4, 4, 8, 4, 8, 4, 6, 8, 6, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 6, 8, 4, 4, 4, 8, 4, 4, 8, 4, 4, 4,\n",
      "        4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 9, 8, 6, 4, 7, 4,\n",
      "        8, 8, 4, 4, 4, 4, 8, 8, 4, 4, 4, 8, 8, 4, 4, 8, 4, 4, 8, 8, 6, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 8, 8, 4, 4, 4, 4, 4, 8, 8, 6, 8, 8, 8, 4, 4, 4, 8, 4, 4,\n",
      "        4, 4, 8, 4, 4, 4, 4, 4, 8, 8, 9, 4, 8, 4, 4, 4, 8, 8, 6, 4, 4, 4, 4, 4,\n",
      "        4, 8, 4, 8, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 8, 8, 8, 6, 4, 4, 4, 4, 4,\n",
      "        9, 4, 4, 4, 4, 6, 8, 8, 4, 4, 4, 8, 4, 4, 8, 8, 8, 4, 4, 8, 4, 8, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4,\n",
      "        6, 4, 4, 6, 4, 4, 4, 8, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4, 6, 4, 4, 4,\n",
      "        8, 4, 8, 4, 4, 4, 4, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1406)\n",
      "\n",
      "tensor(2.2582, grad_fn=<DivBackward1>)\n",
      "tensor([4, 8, 4, 8, 4, 4, 9, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 8, 4, 8, 4, 4, 8, 8, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8,\n",
      "        4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 8, 4, 4, 4, 4, 8, 8,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 6, 9, 4, 4, 8, 4, 8, 4, 6, 8, 6, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 6, 8, 4, 4, 4, 8, 4, 4, 8, 4, 4, 4,\n",
      "        4, 8, 4, 4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 8, 4, 8, 4, 8, 8, 6, 4, 6, 4,\n",
      "        8, 8, 4, 4, 4, 4, 8, 8, 4, 4, 4, 8, 8, 4, 4, 8, 4, 4, 8, 8, 6, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 8, 8, 4, 4, 4, 4, 4, 8, 8, 6, 8, 8, 8, 4, 4, 4, 8, 4, 8,\n",
      "        8, 4, 8, 4, 4, 4, 4, 4, 8, 8, 8, 4, 8, 6, 4, 4, 8, 8, 6, 4, 4, 4, 4, 4,\n",
      "        4, 8, 4, 8, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 8, 8, 8, 6, 4, 4, 4, 6, 4,\n",
      "        8, 4, 4, 4, 4, 6, 8, 8, 4, 4, 4, 8, 4, 4, 8, 8, 8, 4, 4, 8, 4, 8, 4, 4,\n",
      "        8, 4, 4, 4, 8, 4, 4, 4, 8, 8, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4,\n",
      "        6, 4, 4, 6, 4, 4, 4, 8, 4, 4, 8, 4, 4, 8, 4, 4, 8, 4, 4, 4, 6, 4, 4, 4,\n",
      "        8, 4, 8, 8, 4, 8, 4, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1312)\n",
      "\n",
      "tensor(2.2570, grad_fn=<DivBackward1>)\n",
      "tensor([4, 8, 4, 8, 4, 4, 9, 8, 1, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 8, 4, 8, 6, 4, 8, 8, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 8,\n",
      "        4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 8, 4, 4, 4, 4, 8, 8,\n",
      "        4, 4, 4, 4, 4, 4, 8, 1, 4, 6, 4, 8, 6, 9, 4, 4, 8, 4, 8, 4, 6, 0, 6, 4,\n",
      "        6, 4, 4, 4, 4, 6, 4, 4, 8, 4, 8, 4, 6, 8, 4, 4, 4, 8, 4, 4, 8, 4, 4, 4,\n",
      "        4, 8, 4, 4, 6, 4, 4, 4, 4, 8, 4, 4, 4, 4, 8, 4, 8, 4, 8, 8, 6, 4, 6, 4,\n",
      "        8, 8, 4, 4, 4, 4, 8, 8, 4, 4, 4, 8, 8, 1, 4, 0, 4, 4, 8, 8, 6, 4, 4, 4,\n",
      "        4, 4, 8, 4, 4, 8, 8, 4, 4, 4, 4, 4, 8, 8, 6, 8, 8, 8, 4, 4, 4, 8, 4, 8,\n",
      "        8, 4, 8, 4, 4, 4, 4, 4, 8, 8, 9, 4, 8, 6, 4, 4, 8, 8, 6, 4, 4, 4, 4, 4,\n",
      "        4, 8, 4, 8, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 8, 8, 8, 6, 4, 4, 4, 6, 4,\n",
      "        9, 4, 4, 4, 4, 6, 8, 8, 4, 4, 4, 8, 4, 4, 8, 8, 8, 4, 4, 8, 4, 8, 4, 4,\n",
      "        8, 4, 4, 4, 8, 4, 4, 8, 8, 8, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4,\n",
      "        6, 8, 4, 6, 6, 4, 4, 8, 4, 4, 8, 4, 4, 8, 4, 4, 8, 4, 4, 4, 6, 4, 4, 4,\n",
      "        8, 4, 8, 8, 4, 8, 4, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1344)\n",
      "\n",
      "tensor(2.2558, grad_fn=<DivBackward1>)\n",
      "tensor([4, 8, 4, 8, 4, 1, 9, 9, 1, 4, 4, 6, 4, 8, 4, 4, 4, 4, 4, 4, 1, 4, 4, 7,\n",
      "        4, 4, 4, 8, 4, 8, 6, 4, 8, 8, 4, 4, 8, 1, 4, 4, 4, 4, 8, 4, 4, 8, 4, 8,\n",
      "        4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 8, 4, 4, 6, 4, 8, 9,\n",
      "        4, 4, 8, 4, 6, 4, 9, 6, 4, 6, 4, 8, 6, 9, 4, 4, 8, 4, 9, 4, 6, 0, 6, 4,\n",
      "        6, 4, 4, 4, 4, 6, 4, 7, 8, 4, 8, 4, 6, 8, 4, 8, 4, 8, 4, 4, 8, 4, 4, 4,\n",
      "        4, 8, 4, 4, 6, 4, 8, 1, 4, 9, 7, 4, 4, 4, 8, 4, 8, 4, 9, 8, 6, 4, 6, 4,\n",
      "        8, 9, 4, 4, 4, 4, 9, 8, 4, 4, 4, 8, 8, 6, 4, 0, 4, 4, 8, 8, 6, 4, 4, 4,\n",
      "        4, 4, 8, 4, 4, 8, 8, 7, 4, 4, 4, 4, 8, 8, 6, 8, 9, 0, 4, 4, 4, 9, 4, 8,\n",
      "        8, 4, 8, 4, 4, 4, 4, 4, 8, 8, 9, 4, 8, 6, 4, 4, 8, 8, 6, 4, 4, 4, 4, 1,\n",
      "        4, 8, 4, 8, 4, 4, 4, 4, 4, 4, 4, 8, 7, 8, 7, 8, 8, 9, 6, 1, 4, 4, 6, 4,\n",
      "        9, 4, 4, 4, 4, 6, 8, 9, 4, 4, 4, 9, 4, 4, 9, 8, 9, 4, 4, 9, 4, 8, 4, 4,\n",
      "        8, 4, 4, 4, 8, 4, 4, 8, 8, 8, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 8, 4, 4, 4,\n",
      "        6, 8, 4, 6, 6, 4, 4, 8, 4, 9, 8, 4, 4, 8, 4, 4, 8, 4, 4, 4, 6, 4, 1, 4,\n",
      "        8, 4, 8, 8, 4, 8, 4, 8])\n",
      "tensor([5., 2., 6., 6., 2., 1., 7., 4., 9., 5., 2., 2., 2., 0., 9., 8., 7., 6.,\n",
      "        8., 0., 9., 3., 4., 7., 9., 1., 3., 8., 7., 5., 3., 5., 4., 8., 3., 2.,\n",
      "        2., 0., 8., 5., 8., 4., 3., 4., 7., 0., 4., 6., 9., 7., 1., 1., 2., 6.,\n",
      "        0., 9., 5., 6., 1., 4., 1., 9., 9., 8., 9., 0., 7., 7., 6., 9., 8., 9.,\n",
      "        8., 6., 2., 7., 3., 4., 9., 1., 8., 1., 2., 5., 7., 1., 2., 3., 7., 6.,\n",
      "        5., 4., 1., 6., 6., 5., 2., 0., 1., 6., 9., 1., 9., 6., 0., 3., 7., 9.,\n",
      "        6., 9., 4., 9., 4., 0., 5., 3., 5., 2., 5., 9., 8., 0., 4., 7., 1., 5.,\n",
      "        3., 7., 1., 9., 4., 0., 4., 7., 8., 3., 2., 1., 9., 1., 0., 8., 6., 7.,\n",
      "        0., 8., 8., 3., 6., 2., 8., 0., 1., 6., 5., 7., 0., 3., 6., 1., 4., 5.,\n",
      "        7., 9., 3., 6., 6., 7., 6., 0., 5., 8., 4., 2., 3., 8., 4., 3., 3., 5.,\n",
      "        8., 8., 3., 0., 3., 2., 1., 4., 1., 3., 6., 4., 7., 1., 1., 2., 5., 7.,\n",
      "        2., 2., 0., 7., 5., 5., 9., 5., 7., 8., 5., 5., 4., 4., 2., 5., 4., 0.,\n",
      "        2., 0., 0., 0., 7., 8., 8., 9., 8., 4., 7., 9., 1., 8., 7., 0., 0., 9.,\n",
      "        7., 1., 3., 1., 2., 5., 7., 6., 8., 6., 6., 7., 9., 7., 3., 7., 9., 9.,\n",
      "        7., 6., 1., 5., 2., 9., 4., 2., 7., 2., 6., 5., 7., 2., 1., 3., 4., 3.,\n",
      "        7., 0., 4., 8., 4., 4., 3., 7., 9., 9., 8., 3., 4., 4., 5., 3., 4., 8.,\n",
      "        4., 1., 8., 6., 3., 0., 3., 1., 1., 9., 3., 1., 8., 5., 5., 1., 4., 4.,\n",
      "        6., 2., 5., 4., 1., 6., 8., 3., 4., 4., 8., 0., 5., 1.],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Accuracy: tensor(0.1656)\n",
      "\n",
      "tensor(2.2544, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for iepoch in tqdm(range(20)):\n",
    "    optimizer.zero_grad()\n",
    "    X_tensor=torch.tensor(X_train)\n",
    "    predictions=model(X_tensor.float()).squeeze(1)\n",
    "    #predictions=torch.sign(predictions)\n",
    "    #print(predictions)\n",
    "    label=torch.tensor(y_train)\n",
    "    #for i in range(len(label)):\n",
    "    #    if label[i]==1:\n",
    "    #        label[i] = 0\n",
    "    #    else:\n",
    "    #        label[i]=1\n",
    "    #print(label)\n",
    "    loss = criterion(predictions, label.float())\n",
    "    acc = multi_accuracy(predictions, label)\n",
    "    print('')\n",
    "    print('Accuracy:',acc)\n",
    "    print('')\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 4, 5, 7, 6, 6, 4, 4, 7, 9, 8, 4, 4, 9,\n",
      "        4, 8, 8, 7, 4, 7, 4, 4, 4, 9, 9, 4, 7, 7, 9, 5, 1, 6, 7, 9, 9, 7, 7, 9,\n",
      "        8, 4, 7, 7, 7, 9, 9, 4, 8, 7, 1, 4, 7, 6, 9, 8, 7, 4, 4, 7, 7, 9, 6, 6,\n",
      "        6, 9, 4, 9, 9, 8, 8, 9])\n",
      "tensor([9., 4., 3., 3., 4., 8., 6., 7., 2., 5., 2., 7., 8., 1., 6., 5., 4., 6.,\n",
      "        1., 9., 5., 7., 0., 9., 0., 1., 9., 7., 0., 9., 7., 5., 6., 1., 1., 6.,\n",
      "        7., 2., 5., 9., 5., 4., 3., 0., 4., 6., 4., 8., 2., 3., 9., 6., 2., 0.,\n",
      "        4., 5., 4., 8., 1., 8., 3., 7., 2., 9., 7., 3., 1., 6., 2., 8., 4., 0.,\n",
      "        3., 7., 1., 8., 3., 5., 8., 0.], dtype=torch.float64)\n",
      "\n",
      "Accuracy: 0.13750000298023224\n",
      "\n",
      "AUROC: 0.5896150542907368\n",
      "\n",
      "Precision (macro): 0.1161019536019536\n",
      "\n",
      "Recall (macro): 0.12916666666666665\n",
      "\n",
      "F1 Score (macro): 0.1011297852474323\n",
      "\n",
      "AUPRC (macro): 0.17464733801294136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "# Convert test data to tensor\n",
    "X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "predictions = model(X_tensor)\n",
    "\n",
    "# Convert y_train to tensor and change labels from 1 to 0, and 7 to 1\n",
    "label=torch.tensor(y_test)\n",
    "# label = torch.tensor(y_test, dtype=torch.long).clone()  # Ensure labels are LongTensor\n",
    "        \n",
    "# Compute loss\n",
    "loss = criterion(predictions, label)\n",
    "\n",
    "# Convert predictions and labels to numpy for sklearn metrics\n",
    "preds_np = predictions.detach().numpy()  # Detach predictions from the graph and convert to numpy\n",
    "labels_np = label.numpy()  # Convert labels to numpy\n",
    "\n",
    "# Get predicted classes\n",
    "predicted_classes = np.argmax(preds_np, axis=1)\n",
    "\n",
    "# Calculate Accuracy\n",
    "acc = multi_accuracy(predictions, label.float())\n",
    "\n",
    "# Calculate AUROC for each class (one-vs-rest approach)\n",
    "auroc = roc_auc_score(labels_np, preds_np, multi_class=\"ovr\")\n",
    "\n",
    "# Ensure labels_np is in class label form, not one-hot encoded\n",
    "if labels_np.ndim > 1:\n",
    "    labels_np = np.argmax(labels_np, axis=1)\n",
    "\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score (macro average for multi-class)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels_np, predicted_classes, average='macro')\n",
    "\n",
    "# Calculate AUPRC (Area Under the Precision-Recall Curve) for each class\n",
    "auprc = average_precision_score(labels_np, preds_np, average=\"macro\")\n",
    "\n",
    "# Print results\n",
    "print(f'\\nAccuracy: {acc}\\n')\n",
    "# print(f'Loss: {loss}\\n')\n",
    "print(f'AUROC: {auroc}\\n')\n",
    "print(f'Precision (macro): {precision}\\n')\n",
    "print(f'Recall (macro): {recall}\\n')\n",
    "print(f'F1 Score (macro): {f1}\\n')\n",
    "print(f'AUPRC (macro): {auprc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
