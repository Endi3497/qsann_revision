{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 00:43:15.604030: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 00:43:15.620646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-20 00:43:15.639136: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-20 00:43:15.644700: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 00:43:15.659109: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 00:43:16.621064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 160\n",
      "Test set size: 40\n",
      "Sampled train labels: [0 1]\n",
      "Sampled test labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CIFAR-10 데이터 불러오기\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = cifar10.load_data()\n",
    "\n",
    "# 데이터 정규화 (0-255 값을 0-1 사이로)\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test_full = X_test_full.astype('float32') / 255.0\n",
    "\n",
    "# RGB -> Grayscale 변환\n",
    "# 공식: 0.299*R + 0.587*G + 0.114*B\n",
    "X_train_gray = np.dot(X_train_full[...,:3], [0.299, 0.587, 0.114])\n",
    "X_test_gray = np.dot(X_test_full[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "# 원하는 두 개의 클래스만 선택 (예: 클래스 0과 1)\n",
    "selected_classes = [0, 1]\n",
    "\n",
    "# 클래스 0과 1에 해당하는 데이터만 선택 (train set)\n",
    "train_mask = np.isin(y_train_full, selected_classes)\n",
    "X_train_filtered = X_train_gray[train_mask.squeeze()]\n",
    "y_train_filtered = y_train_full[train_mask.squeeze()]\n",
    "\n",
    "# 클래스 0과 1에 해당하는 데이터만 선택 (test set)\n",
    "test_mask = np.isin(y_test_full, selected_classes)\n",
    "X_test_filtered = X_test_gray[test_mask.squeeze()]\n",
    "y_test_filtered = y_test_full[test_mask.squeeze()]\n",
    "\n",
    "# 클래스 라벨을 이진 라벨로 변환 (0 또는 1로)\n",
    "y_train_filtered = (y_train_filtered == selected_classes[1]).astype(int)\n",
    "y_test_filtered = (y_test_filtered == selected_classes[1]).astype(int)\n",
    "\n",
    "# 시드 고정\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2000개의 데이터를 무작위로 선택\n",
    "num_samples = 200\n",
    "indices = np.random.choice(len(X_train_filtered), num_samples, replace=False)\n",
    "X_sampled, y_sampled = X_train_filtered[indices], y_train_filtered[indices]\n",
    "\n",
    "# 2000개의 샘플에서 train/test 데이터 분할 (80% train, 20% test 비율로 나눔)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sampled, y_sampled, stratify=y_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train = y_train.squeeze(1)\n",
    "y_test = y_test.squeeze(1)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Sampled train labels: {np.unique(y_train)}\")\n",
    "print(f\"Sampled test labels: {np.unique(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6611, Accuracy: 51.25%\n",
      "Epoch [2/10], Loss: 0.6008, Accuracy: 61.88%\n",
      "Epoch [3/10], Loss: 0.6080, Accuracy: 61.88%\n",
      "Epoch [4/10], Loss: 0.4609, Accuracy: 70.00%\n",
      "Epoch [5/10], Loss: 0.4310, Accuracy: 78.75%\n",
      "Epoch [6/10], Loss: 0.3684, Accuracy: 78.75%\n",
      "Epoch [7/10], Loss: 0.2972, Accuracy: 82.50%\n",
      "Epoch [8/10], Loss: 0.2273, Accuracy: 84.38%\n",
      "Epoch [9/10], Loss: 0.1892, Accuracy: 81.88%\n",
      "Epoch [10/10], Loss: 0.2363, Accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # 채널 차원 추가\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 데이터셋과 데이터 로더 정의\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# CNN 모델 정의\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNNModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels = labels.unsqueeze(1)  # BCELoss에 맞추어 차원 맞추기\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy 계산\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {train_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: conv1.weight\n",
      "Shape: torch.Size([32, 1, 3, 3])\n",
      "Number of parameters: 288\n",
      "--------------------------------------------------\n",
      "Parameter name: conv1.bias\n",
      "Shape: torch.Size([32])\n",
      "Number of parameters: 32\n",
      "--------------------------------------------------\n",
      "Parameter name: conv2.weight\n",
      "Shape: torch.Size([64, 32, 3, 3])\n",
      "Number of parameters: 18432\n",
      "--------------------------------------------------\n",
      "Parameter name: conv2.bias\n",
      "Shape: torch.Size([64])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: fc1.weight\n",
      "Shape: torch.Size([128, 4096])\n",
      "Number of parameters: 524288\n",
      "--------------------------------------------------\n",
      "Parameter name: fc1.bias\n",
      "Shape: torch.Size([128])\n",
      "Number of parameters: 128\n",
      "--------------------------------------------------\n",
      "Parameter name: fc2.weight\n",
      "Shape: torch.Size([1, 128])\n",
      "Number of parameters: 128\n",
      "--------------------------------------------------\n",
      "Parameter name: fc2.bias\n",
      "Shape: torch.Size([1])\n",
      "Number of parameters: 1\n",
      "--------------------------------------------------\n",
      "Total number of trainable parameters: 543361\n"
     ]
    }
   ],
   "source": [
    "# Print out the parameters and their shapes\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(f\"Number of parameters: {param.numel()}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.50%\n",
      "AUROC: 0.9550\n",
      "Precision: 0.9048\n",
      "Recall: 0.9500\n",
      "F1 Score: 0.9268\n",
      "AUPRC: 0.9197\n"
     ]
    }
   ],
   "source": [
    "# 테스트 평가\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.unsqueeze(1)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "# 평가 지표 계산\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# 이진 분류 결과 계산\n",
    "test_accuracy = accuracy_score(all_labels, all_preds > 0.5)\n",
    "test_roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds > 0.5)\n",
    "test_recall = recall_score(all_labels, all_preds > 0.5)\n",
    "test_f1 = f1_score(all_labels, all_preds > 0.5)\n",
    "test_auprc = average_precision_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"AUROC: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"AUPRC: {test_auprc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
