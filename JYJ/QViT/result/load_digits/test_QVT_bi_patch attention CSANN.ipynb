{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.images, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "train_mask = np.isin(y_train, [1, 7])\n",
    "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "\n",
    "test_mask = np.isin(y_test, [1, 7])\n",
    "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "\n",
    "#\n",
    "# X_train = X_train.reshape(X_train.shape[0], 16, 4)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 크기로 겹치지 않게 패치로 나누는 함수\n",
    "def split_into_non_overlapping_patches(image, patch_size=(4, 4)):\n",
    "    patches = []\n",
    "    for i in range(0, image.shape[0], patch_size[0]):\n",
    "        for j in range(0, image.shape[1], patch_size[1]):\n",
    "            patch = image[i:i+patch_size[0], j:j+patch_size[1]].flatten()\n",
    "            patches.append(patch)\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지를 2x2 겹치지 않는 패치로 나누기\n",
    "X_train = np.array([split_into_non_overlapping_patches(img) for img in X_train])\n",
    "X_test = np.array([split_into_non_overlapping_patches(img) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 145, 7: 138}\n"
     ]
    }
   ],
   "source": [
    "# y_train이 numpy 배열일 경우\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 37, 7: 41}\n"
     ]
    }
   ],
   "source": [
    "# y_train이 numpy 배열일 경우\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 4, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Self-Attention and Binary Classifier from previous code\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert self.head_dim * heads == embed_size, \"Embedding size must be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask=None):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        # Split embedding into multiple heads\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "# Classifier model\n",
    "class SimpleSelfAttentionClassifier(nn.Module):\n",
    "    def __init__(self, embed_size=16, heads=2, num_classes=2):\n",
    "        super(SimpleSelfAttentionClassifier, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.fc = nn.Linear(embed_size * 4, num_classes)  # 49 is the sequence length in X_train\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output = self.attention(x, x, x)\n",
    "        attention_output = attention_output.flatten(start_dim=1)  # Flatten to feed into classifier\n",
    "        out = self.fc(attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, loss, optimizer\n",
    "model = SimpleSelfAttentionClassifier(embed_size=16, heads=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def binary_accuracy(preds, y):\n",
    "#     \"\"\"\n",
    "#     Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "#     \"\"\"\n",
    "\n",
    "#     #round predictions to the closest integer\n",
    "#     rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
    "#     correct = (rounded_preds == y).float() #convert into float for division \n",
    "#     acc = correct.sum() / len(correct)\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your binary accuracy function\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4452296793460846\n",
      "Loss: 1.6707100868225098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:01<00:35,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete\n",
      "Accuracy: 0.47703179717063904\n",
      "Loss: 1.4804553985595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete\n",
      "Accuracy: 0.4416961073875427\n",
      "Loss: 1.3364660739898682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:04<00:24,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete\n",
      "Accuracy: 0.44876325130462646\n",
      "Loss: 1.2355749607086182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:05<00:22,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete\n",
      "Accuracy: 0.45229682326316833\n",
      "Loss: 1.1689460277557373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:07<00:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete\n",
      "Accuracy: 0.4805653691291809\n",
      "Loss: 1.1224044561386108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:08<00:20,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 complete\n",
      "Accuracy: 0.4699646532535553\n",
      "Loss: 1.0816353559494019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:10<00:17,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 complete\n",
      "Accuracy: 0.5159010887145996\n",
      "Loss: 1.0370538234710693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:11<00:17,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 complete\n",
      "Accuracy: 0.565371036529541\n",
      "Loss: 0.9853075742721558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:13<00:17,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 complete\n",
      "Accuracy: 0.5901060104370117\n",
      "Loss: 0.9278027415275574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:15<00:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 complete\n",
      "Accuracy: 0.6113074421882629\n",
      "Loss: 0.8683762550354004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:17<00:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 complete\n",
      "Accuracy: 0.6431095600128174\n",
      "Loss: 0.8113340735435486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:19<00:13,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 complete\n",
      "Accuracy: 0.6501767039299011\n",
      "Loss: 0.7600891590118408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:20<00:12,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 complete\n",
      "Accuracy: 0.6537102460861206\n",
      "Loss: 0.716379702091217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:22<00:10,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 complete\n",
      "Accuracy: 0.6678445339202881\n",
      "Loss: 0.6800748109817505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:24<00:08,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 complete\n",
      "Accuracy: 0.6819788217544556\n",
      "Loss: 0.6495567560195923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:26<00:06,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 complete\n",
      "Accuracy: 0.7067137956619263\n",
      "Loss: 0.6225188970565796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:29<00:06,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 complete\n",
      "Accuracy: 0.7173144817352295\n",
      "Loss: 0.5968416929244995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:32<00:04,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 complete\n",
      "Accuracy: 0.7208480834960938\n",
      "Loss: 0.5712011456489563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:34<00:02,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 complete\n",
      "Accuracy: 0.7420494556427002\n",
      "Loss: 0.5452451705932617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:36<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for iepoch in tqdm(range(20)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Convert your X_train into tensor\n",
    "    X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(X_tensor)\n",
    "    \n",
    "    # Convert y_train to tensor and change labels from 1 to 0, and 7 to 1\n",
    "    label = torch.tensor(y_train, dtype=torch.long).clone()  # Ensure labels are LongTensor\n",
    "    for i in range(len(label)):\n",
    "        label[i] = 0 if label[i] == 1 else 1  # 1 -> 0, 7 -> 1\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(predictions, label)\n",
    "    \n",
    "    # Calculate binary accuracy (adjusted for your binary classification)\n",
    "    acc = binary_accuracy(predictions.argmax(dim=1), label)\n",
    "    \n",
    "    # Print accuracy and loss\n",
    "    print(f'Accuracy: {acc}')\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    \n",
    "    # Backward pass and optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {iepoch+1} complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7692307829856873\n",
      "\n",
      "Loss: 0.5283698439598083\n",
      "\n",
      "AUROC: 0.8226763348714569\n",
      "\n",
      "Precision: 0.7948717948717948\n",
      "\n",
      "Recall: 0.7560975609756098\n",
      "\n",
      "F1 Score: 0.775\n",
      "\n",
      "AUPRC: 0.7570751154003538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "# Convert test data to tensor\n",
    "X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "predictions = model(X_tensor)\n",
    "\n",
    "# Convert y_train to tensor and change labels from 1 to 0, and 7 to 1\n",
    "label = torch.tensor(y_test, dtype=torch.long).clone()  # Ensure labels are LongTensor\n",
    "        \n",
    "# Reverse the labels (if needed)\n",
    "for i in range(len(label)):\n",
    "    if label[i] == 1:\n",
    "        label[i] = 0\n",
    "    else:\n",
    "        label[i] = 1\n",
    "\n",
    "# Calculate loss and accuracy\n",
    "# Compute loss\n",
    "loss = criterion(predictions, label)\n",
    "\n",
    "# Calculate binary accuracy (adjusted for your binary classification)\n",
    "acc = binary_accuracy(predictions.argmax(dim=1), label)\n",
    "\n",
    "# Convert predictions to probabilities using softmax\n",
    "probabilities = torch.softmax(predictions, dim=1)  # Shape: (batch_size, 2)\n",
    "\n",
    "# Extract probabilities for class 1 (positive class)\n",
    "positive_class_probs = probabilities[:, 1].detach().numpy()\n",
    "\n",
    "# Convert labels to numpy\n",
    "labels_np = label.numpy()\n",
    "\n",
    "# Calculate AUROC\n",
    "auroc = roc_auc_score(labels_np, positive_class_probs)\n",
    "\n",
    "# Binarize predictions for precision, recall, and F1 calculation\n",
    "binary_preds = np.where(positive_class_probs > 0.5, 1, 0)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels_np, binary_preds, average='binary')\n",
    "\n",
    "# Calculate AUPRC (Area Under the Precision-Recall Curve)\n",
    "auprc = average_precision_score(labels_np, positive_class_probs)\n",
    "\n",
    "# Print results\n",
    "print(f'\\nAccuracy: {acc}\\n')\n",
    "print(f'Loss: {loss}\\n')\n",
    "print(f'AUROC: {auroc}\\n')\n",
    "print(f'Precision: {precision}\\n')\n",
    "print(f'Recall: {recall}\\n')\n",
    "print(f'F1 Score: {f1}\\n')\n",
    "print(f'AUPRC: {auprc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
