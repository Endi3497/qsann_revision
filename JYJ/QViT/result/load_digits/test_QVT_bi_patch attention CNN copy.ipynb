{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6397, Accuracy: 60.00%\n",
      "Epoch [2/10], Loss: 0.4801, Accuracy: 89.38%\n",
      "Epoch [3/10], Loss: 0.2488, Accuracy: 98.12%\n",
      "Epoch [4/10], Loss: 0.1169, Accuracy: 97.50%\n",
      "Epoch [5/10], Loss: 0.0729, Accuracy: 100.00%\n",
      "Epoch [6/10], Loss: 0.0181, Accuracy: 100.00%\n",
      "Epoch [7/10], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [8/10], Loss: 0.0088, Accuracy: 100.00%\n",
      "Epoch [9/10], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [10/10], Loss: 0.0027, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# load_digits 데이터셋 로드\n",
    "digits = load_digits()\n",
    "X_full, y_full = digits.data, digits.target\n",
    "\n",
    "# 숫자 1과 7에 해당하는 데이터만 필터링\n",
    "class1_indices = np.where(y_full == 1)[0][:100]\n",
    "class7_indices = np.where(y_full == 7)[0][:100]\n",
    "selected_indices = np.concatenate([class1_indices, class7_indices])\n",
    "\n",
    "X_filtered = X_full[selected_indices]\n",
    "y_filtered = y_full[selected_indices]\n",
    "\n",
    "# 레이블 이진화: 1 -> 0, 7 -> 1\n",
    "y_filtered = (y_filtered == 7).astype(int)\n",
    "\n",
    "# 데이터 정규화 (0-16 값을 0-1 사이로)\n",
    "X_filtered = X_filtered / 16.0\n",
    "\n",
    "# 데이터 차원 변환: CNN 입력에 맞게 8x8 이미지 형태로 재구성\n",
    "X_filtered = X_filtered.reshape(-1, 8, 8)\n",
    "\n",
    "# Stratify 방식으로 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, stratify=y_filtered, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # 채널 차원 추가\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 데이터셋과 데이터 로더 정의\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# CNN 모델 정의\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 2 * 2)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNNModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels = labels.unsqueeze(1)  # BCELoss에 맞추어 차원 맞추기\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy 계산\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {train_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: conv1.weight\n",
      "Shape: torch.Size([32, 1, 3, 3])\n",
      "Number of parameters: 288\n",
      "--------------------------------------------------\n",
      "Parameter name: conv1.bias\n",
      "Shape: torch.Size([32])\n",
      "Number of parameters: 32\n",
      "--------------------------------------------------\n",
      "Parameter name: conv2.weight\n",
      "Shape: torch.Size([64, 32, 3, 3])\n",
      "Number of parameters: 18432\n",
      "--------------------------------------------------\n",
      "Parameter name: conv2.bias\n",
      "Shape: torch.Size([64])\n",
      "Number of parameters: 64\n",
      "--------------------------------------------------\n",
      "Parameter name: fc1.weight\n",
      "Shape: torch.Size([128, 256])\n",
      "Number of parameters: 32768\n",
      "--------------------------------------------------\n",
      "Parameter name: fc1.bias\n",
      "Shape: torch.Size([128])\n",
      "Number of parameters: 128\n",
      "--------------------------------------------------\n",
      "Parameter name: fc2.weight\n",
      "Shape: torch.Size([1, 128])\n",
      "Number of parameters: 128\n",
      "--------------------------------------------------\n",
      "Parameter name: fc2.bias\n",
      "Shape: torch.Size([1])\n",
      "Number of parameters: 1\n",
      "--------------------------------------------------\n",
      "Total number of trainable parameters: 51841\n"
     ]
    }
   ],
   "source": [
    "# Print out the parameters and their shapes\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(f\"Number of parameters: {param.numel()}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n",
      "AUROC: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "AUPRC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 테스트 평가\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.unsqueeze(1)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "# 평가 지표 계산\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# 이진 분류 결과 계산\n",
    "test_accuracy = accuracy_score(all_labels, all_preds > 0.5)\n",
    "test_roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds > 0.5)\n",
    "test_recall = recall_score(all_labels, all_preds > 0.5)\n",
    "test_f1 = f1_score(all_labels, all_preds > 0.5)\n",
    "test_auprc = average_precision_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"AUROC: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"AUPRC: {test_auprc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
