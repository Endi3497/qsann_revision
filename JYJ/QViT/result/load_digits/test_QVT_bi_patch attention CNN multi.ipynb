{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.images, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "train_mask = np.isin(y_train, [0, 1, 7])\n",
    "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "\n",
    "test_mask = np.isin(y_test, [0, 1, 7])\n",
    "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "\n",
    "# y_train과 y_test에서 7을 2로 변환\n",
    "y_train = np.where(y_train == 7, 2, y_train)\n",
    "y_test = np.where(y_test == 7, 2, y_test)\n",
    "\n",
    "#\n",
    "# X_train = X_train.reshape(X_train.shape[0], 16, 4)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:03:44.830049: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-18 12:03:44.847334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-18 12:03:44.867773: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-18 12:03:44.874011: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 12:03:44.892461: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 12:03:45.776721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# X_train과 y_train이 올바르게 변환되고 동일한 첫 번째 차원을 가지는지 확인\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # 채널 차원 추가\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)  # 다중 클래스 분류를 위해 정수형 변환\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "# 데이터셋과 데이터 로더 정의\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# CNN 모델 정의\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 클래스 개수에 맞게 설정\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 2 * 2)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # CrossEntropyLoss는 로짓을 기대하므로 sigmoid 사용 안 함\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    배치별 정확도를 반환합니다 (예: 8/10 개 정답인 경우 0.8 반환)\n",
    "    \"\"\"\n",
    "    pred_soft = torch.log_softmax(preds, dim=1)\n",
    "    _, pred_index = torch.max(pred_soft, dim=1)\n",
    "    correct_pred = (pred_index == y).float()  # y와 pred_index 모두 [batch_size] 형태로 맞춤\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 1/10, 정확도: 0.3469, 손실: 1.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeob/anaconda3/envs/lstm/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 2/10, 정확도: 0.5215, 손실: 1.0992\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 3/10, 정확도: 0.6435, 손실: 0.8626\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 4/10, 정확도: 0.9689, 손실: 0.6928\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 5/10, 정확도: 0.7129, 손실: 0.6346\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 6/10, 정확도: 0.8684, 손실: 0.5196\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 7/10, 정확도: 0.9809, 손실: 0.4105\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 8/10, 정확도: 0.9713, 손실: 0.3537\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 9/10, 정확도: 0.9593, 손실: 0.3012\n",
      "Predictions shape: torch.Size([418, 3]), dtype: torch.float32\n",
      "Label shape: torch.Size([418]), dtype: torch.int64\n",
      "에포크 10/10, 정확도: 0.9880, 손실: 0.2279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 입력 텐서 변환 (추가 차원 제거하여 [batch_size, 1, 28, 28] 형태로 만듦)\n",
    "    X_tensor = X_train.clone().detach().float()  # [batch_size, 1, 28, 28]\n",
    "    predictions = model(X_tensor)  # [batch_size, num_classes] 형태의 로짓 출력\n",
    "\n",
    "    # 레이블이 원-핫 인코딩된 경우 클래스 인덱스로 변환\n",
    "    label = y_train.clone().detach().long()\n",
    "    if label.dim() > 1 and label.size(1) > 1:  # 원-핫 인코딩 여부 확인\n",
    "        label = torch.argmax(label, dim=1)  # 클래스 인덱스로 변환하여 [batch_size] 형태로 맞춤\n",
    "\n",
    "    # `predictions`와 `label`의 형식 확인\n",
    "    print(f\"Predictions shape: {predictions.shape}, dtype: {predictions.dtype}\")\n",
    "    print(f\"Label shape: {label.shape}, dtype: {label.dtype}\")\n",
    "\n",
    "    # 손실 및 정확도 계산\n",
    "    loss = criterion(predictions, label)\n",
    "    acc = multi_accuracy(predictions, label)\n",
    "    print(f'에포크 {epoch + 1}/{num_epochs}, 정확도: {acc:.4f}, 손실: {loss.item():.4f}')\n",
    "    \n",
    "    # 역전파 및 옵티마이저 스텝\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "정확도: 1.0\n",
      "\n",
      "AUROC: 1.0\n",
      "\n",
      "정밀도 (macro): 1.0\n",
      "\n",
      "재현율 (macro): 1.0\n",
      "\n",
      "F1 점수 (macro): 1.0\n",
      "\n",
      "AUPRC (macro): 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "# 테스트 데이터 텐서로 변환\n",
    "X_tensor = X_test.clone().detach().float()  # X_test 사용, [batch_size, 1, 28, 28] 형태 예상\n",
    "predictions = model(X_tensor)  # [batch_size, num_classes] 형태의 출력\n",
    "\n",
    "# 소프트맥스를 적용하여 확률로 변환\n",
    "predictions = torch.softmax(predictions, dim=1)\n",
    "\n",
    "# 레이블이 원-핫 인코딩된 경우 클래스 인덱스로 변환\n",
    "label = y_test.clone().detach().long()  # y_test 사용\n",
    "if label.dim() > 1 and label.size(1) > 1:  # 원-핫 인코딩 여부 확인\n",
    "    label = torch.argmax(label, dim=1)  # 클래스 인덱스로 변환하여 [batch_size] 형태로 맞춤\n",
    "\n",
    "# 손실 계산\n",
    "loss = criterion(predictions, label)\n",
    "\n",
    "# sklearn 지표 계산을 위해 predictions와 labels를 numpy 배열로 변환\n",
    "preds_np = predictions.detach().numpy()  # 그래프에서 분리하여 numpy로 변환\n",
    "labels_np = label.numpy()  # 레이블도 numpy로 변환\n",
    "\n",
    "# 예측된 클래스 가져오기\n",
    "predicted_classes = np.argmax(preds_np, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "acc = multi_accuracy(predictions, label)\n",
    "\n",
    "# AUROC (클래스별 one-vs-rest 방식) 계산\n",
    "auroc = roc_auc_score(labels_np, preds_np, multi_class=\"ovr\")\n",
    "\n",
    "# labels_np가 원-핫 인코딩이 아닌 클래스 레이블 형식인지 확인\n",
    "if labels_np.ndim > 1:\n",
    "    labels_np = np.argmax(labels_np, axis=1)\n",
    "\n",
    "# 정밀도, 재현율, F1 점수 계산 (다중 클래스의 경우 macro 평균)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels_np, predicted_classes, average='macro')\n",
    "\n",
    "# 각 클래스에 대한 AUPRC (정밀-재현 곡선 아래 영역) 계산\n",
    "auprc = average_precision_score(labels_np, preds_np, average=\"macro\")\n",
    "\n",
    "# 결과 출력\n",
    "print(f'\\n정확도: {acc}\\n')\n",
    "print(f'AUROC: {auroc}\\n')\n",
    "print(f'정밀도 (macro): {precision}\\n')\n",
    "print(f'재현율 (macro): {recall}\\n')\n",
    "print(f'F1 점수 (macro): {f1}\\n')\n",
    "print(f'AUPRC (macro): {auprc}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
